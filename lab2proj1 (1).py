# -*- coding: utf-8 -*-
"""lab2proj1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JcdMUrC1kI-jQDdzDdYXLD5XlB_Mxa7A
"""

from google.colab import files, drive
drive.mount('/content/drive')

"""#1. Load Data
In this lab, we are going to use the Pima Indians onset of diabetes dataset. It describes patient medical record data for Pima Indians ad whether they had an onset of diabetes within five years. 

As such, it is a binary classification problem (onset of diabetes as 1 or as not as 0). All of the input variables that descrbe each patient are numerical. This makes it easy to use directly with nural networks that expect numerical input and output values, and ideal for our first neural network in Keras. 

"""

from keras.models import Sequential
from keras.layers import Dense
import numpy 
import warnings
warnings.filterwarnings("ignore")
numpy.random.seed(8)


# We can load the file directly using the Numpy function loadtxt(). 
dataset = numpy.loadtxt("/content/drive/MyDrive/lab2/pima-indians-diabetes.csv",delimiter=",")

# There are eight input variables and one output vairables (the last column). 
# Once loaded we can split the dataset into input variables (X) and the output class varible (Y)
X = dataset[:,0:8]
Y = dataset [:,8]

"""#2. Define Model
Models in Keras are defined as a sequence of layers. In this lab, we will use a fully-connected network structure.
"""

model = Sequential()
model.add(Dense(12,input_dim=8, activation='relu'))
model.add(Dense(8,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

"""#3. Compile Model
Now that the model is defined, we can compile it. 
"""

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

"""#4. Fit Model
We have defined our model and compiled it ready for efficient computation. Now it is time to execute the model on somce data
"""

model.fit(train_X,train_Y, epochs=150, batch_size=10)

"""#5. Evaluate Model"""

scores = model.evaluate(train_X, train_Y)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

scores = model.evaluate(test_X, test_Y)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
# To evaluate the performance of the model, we can simply pass the test to the evaluate method of our model.
# To check the test accuracy and loss, execute the script and we can see that we get a test accuracy of 78.57%
# Our training accuaracy was around 81%. This means that our model is slightly overfitting on the training set.

n = len(X)
training_size = int(n*0.8)
testing_size = n-training_size

train_X = X[:training_size,:]
print(train_X)
train_Y = Y[:training_size]
print(train_Y)
test_X = X[:testing_size,:]
test_Y = Y[:testing_size]   # After complete this step, go back and re do step 4